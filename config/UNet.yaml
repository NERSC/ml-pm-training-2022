base: &base

  # Training config
  weight_init: {conv_init: 'normal', conv_scale: 0.02, conv_bias: 0.}
  lambda_rho: 1E-2 # weight for additional rho loss term
  full_scale: True # whether or not to use all 6 of the scales in U-Net
  batch_size: 1
  num_epochs: 2
  enable_amp: False
  enable_apex: False
  enable_benchy: False
  enable_jit: False
  ngpu: 1
  expdir: '/logs'
  # params for setting learning rate (cosine decay schedule):
  #   start_lr: initial learning rate
  #   end_lr:  final learning rate
  #   warmup_steps: number of steps over which to do linear warm-up of learning rate
  #                 *not used when training single-GPU or when scaling='none'*
  #   scaling: 'none' initial lr doesn't change with respect to number of GPUs (use for strong scaling)
  #            'linear' scale up according to lr_nGPU = nGPUs*lr_1GPU
  #            'sqrt' scale up according to lr_nGPU = sqrt(nGPUs)*lr_1GPU
  lr_schedule: {scaling: 'none', start_lr: 1.E-4, end_lr: 0., warmup_steps: 0}

  # Data
  data_loader_config: 'synthetic' # choices: 'synthetic', 'inmem', 'lowmem', 'dali-lowmem'
  box_size: [1024, 512] # total size of simulation boxes (train, validation)
  data_size: 256 # size of crops for training
  num_data_workers: 2 # number of dataloader worker threads per proc
  N_out_channels: 5
  # HDF5 files for PyTorch native dataloader
  train_path: '/data/downsamp_2048crop_train.h5'
  val_path: '/data/downsamp_1024crop_valid.h5'
  # numpy files for DALI dataloader
  train_path_npy_data: '/data/downsamp_2048crop_train_data.npy'
  train_path_npy_label: '/data/downsamp_2048crop_train_label.npy'
  val_path_npy_data: '/data/downsamp_1024crop_valid_data.npy'
  val_path_npy_label: '/data/downsamp_1024crop_valid_label.npy'
  use_cache: None # set this to a cache dir (e.g., NVMe on CoriGPU) if you copied data there


#------------------------------------------------------------------------

# A100 configs: for Perlmutter (crop sizes 64 and 96)

#------------------------------------------------------------------------

#                       ----   CROP SIZE 64   ----


A100_crop64_sqrt: &crop64_A100
  <<: *base
  data_loader_config: 'lowmem'
  data_size: 64
  Nsamples: 4096
  Nsamples_val: 512
  num_epochs: 80
  batch_size: 64
  lr_schedule: {scaling: 'sqrt', start_lr: 2.E-4, end_lr: 0., warmup_steps: 128}
  lambda_rho: 0.


#                       ----   CROP SIZE 96   ----


A100_crop96_sqrt: &crop96_A100
  <<: *base
  data_loader_config: 'lowmem'
  data_size: 96
  Nsamples: 4096
  Nsamples_val: 256
  num_epochs: 80
  full_scale: False
  batch_size: 64
  lr_schedule: {scaling: 'sqrt', start_lr: 2.E-4, end_lr: 0., warmup_steps: 128}
  lambda_rho: 0.

